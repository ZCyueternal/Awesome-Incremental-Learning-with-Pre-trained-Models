# Awesome Incremental Learning with Pre-trained Models[![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

![](https://img.shields.io/badge/AILpapers-v1.0-orange)
![](https://img.shields.io/github/stars/sun-hailong/Awesome-Incremental-Learning-with-Pre-trained-Model?style=social)
[![Hits](https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fgithub.com%2Fsun-hailong%2FAwesome-Incremental-Learning-with-Pre-trained-Model&count_bg=%2379C83D&title_bg=%23555555&icon=&icon_color=%23E7E7E7&title=hits&edge_flat=false)](https://hits.seeyoufarm.com)
![](https://black.readthedocs.io/en/stable/_static/license.svg)

## ðŸ¤— Contributing
### ðŸš€Feel free to [contact me]() or add [pull request](https://github.com/sun-hailong/Awesome-Incremental-Learning-with-Pre-trained-Model/pulls) if you findðŸ‘€ any interesting paper is missing.

<p align="center">
  <img src="http://cdn1.sportngin.com/attachments/news_article/7269/5172/needyou_small.jpg" alt="We Need You!">
</p>

ðŸ“‹Markdown format:
```markdown
- Paper Name. (**Conference Year**) [[paper](link)] [[code](link)]
```

## ðŸ“‘Papers

### 2023
- Revisiting Class-Incremental Learning with Pre-Trained Models: Generalizability and Adaptivity are All You Need (**arXiv23**)[[paper](https://arxiv.org/abs/2303.07338)] [[code](https://github.com/zhoudw-zdw/RevisitingCIL)]
- PromptFusion: Decoupling Stability and Plasticity for Continual Learning (**arXiv23**)[[paper](https://arxiv.org/abs/2303.07223)]
- Preventing Zero-Shot Transfer Degradation in Continual Learning of Vision-Language Models (**arXiv23**)[[paper](https://arxiv.org/abs/2303.06628)] [[code](https://github.com/Thunderbeee/ZSCL)]
- A Unified Continual Learning Framework with General Parameter-Efficient Tuning (**arXiv23**)[[paper](https://arxiv.org/abs/2303.10070)] [[code](https://github.com/gqk/LAE)]
- SLCA: Slow Learner with Classifier Alignment for Continual Learning on a Pre-trained Model (**arXiv23**)[[paper](https://arxiv.org/abs/2303.05118)]
- PLOT: Prompt Learning with Optimal Transport for Vision-Language Models (**ICLR23**)[[paper](https://arxiv.org/abs/2210.01253)] [[code](https://github.com/CHENGY12/PLOT)]
- CODA-Prompt: COntinual Decomposed Attention-based Prompting for Rehearsal-Free Continual Learning (**CVPR23**)[[paper](https://arxiv.org/abs/2211.13218)] [[code](https://github.com/GT-RIPL/CODA-Prompt)]
- Isolation and Impartial Aggregation: A Paradigm of Incremental Learning without Interference (**AAAI23**)[[paper](https://arxiv.org/abs/2211.15969)] [[code](https://github.com/iamwangyabin/ESN)]
- PIVOT: Prompting for Video Continual Learning (**CVPR23**)[[paper](https://arxiv.org/abs/2212.04842)]
- Deep Class-Incremental Learning: A Survey (**arXiv23**)[[paper](https://arxiv.org/abs/2302.03648)] [[code](https://github.com/zhoudw-zdw/CIL_Survey)]
- DualHSIC: HSIC-Bottleneck and Alignment for Continual Learning (**ICML23**)[[paper](https://arxiv.org/abs/2305.00380)]
- Learning Expressive Prompting With Residuals for Vision Transformers (**CVPR23**)[[paper](https://arxiv.org/abs/2303.15591)]
- Learning with Fantasy: Semantic-Aware Virtual Contrastive Constraint for Few-Shot Class-Incremental Learning (**CVPR23**)[[paper](https://arxiv.org/abs/2304.00426)] [[code](https://github.com/zysong0113/SAVC)]
- Multimodal Parameter-Efficient Few-Shot Class Incremental Learning (**arXiv23**)[[paper](https://arxiv.org/abs/2303.04751)]
- Real-Time Evaluation in Online Continual Learning: A New Hope (**CVPR23 Highlight**)[[paper](https://arxiv.org/abs/2302.01047)]


### 2022
- Class-Incremental Learning with Strong Pre-trained Models (**CVPR22**)[[paper](https://arxiv.org/abs/2204.03634)] [[code](https://github.com/amazon-science/sp-cil)]
- Learning to Prompt for Continual Learning (**CVPR22**)[[paper](https://arxiv.org/abs/2112.08654)] [[code](https://github.com/google-research/l2p)]
- S-Prompts Learning with Pre-trained Transformers: An Occam's Razor for Domain Incremental Learning (**NeurIPS22**)[[paper](https://arxiv.org/abs/2207.12819)] [[code]( https://github.com/iamwangyabin/S-Prompts)]
- Don't Stop Learning: Towards Continual Learning for the CLIP Model (**arXiv22**)[[paper](https://arxiv.org/abs/2207.09248)]
- DualPrompt: Complementary Prompting for Rehearsal-free Continual Learning (**ECCV22**)[[paper](https://arxiv.org/abs/2204.04799)] [[code](https://github.com/google-research/l2p)]
- Incremental Prompting: Episodic Memory Prompt for Lifelong Event Detection (**COLING22**)[[paper](https://arxiv.org/abs/2204.07275)]
- Momentum-based Weight Interpolation of Strong Zero-Shot Models for Continual Learning (**NeurIPS22**)[[paper](https://arxiv.org/abs/2204.07275)]
- Prompt Conditioned VAE: Enhancing Generative Replay for Lifelong Learning in Task-Oriented Dialogue(**ENNLP22**)[[paper](https://arxiv.org/abs/2210.07783)]

### 2021
